{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNoydh-RsgcD"
      },
      "source": [
        "  # Introduction\n",
        "\n",
        "In this tutorial, we will demonstrate how to apply a pre-trained AI model to segment the CTV and OARs on T2w-MRI prostate scans.\n",
        "\n",
        "## Requirements\n",
        "* Python>=3.8\n",
        "* Applying this model requires access to a GPU.  \n",
        "  *On Colab* :  `Runtime > Change runtime type > Select GPU `\n",
        "\n",
        "## AI model\n",
        "* The segmentation model used here was trained and validated on T2w-MR scans used for RT planning. Its performance on diagnostic scans is expected to be sub-optimal.\n",
        "* The trained model is packaged as a Conda environment archive containing  python libraries and other dependencies.\n",
        "\n",
        "## I/O\n",
        "* **Input**: DICOM-format T2w-MR scan(s) of the prostate.  \n",
        "  \n",
        "* **Output**: DICOM RTStruct-format segmentations.  \n",
        "  \n",
        "  \n",
        "  Input data should be organized as: one directory of DICOM images per patient.      \n",
        "  \n",
        "    \n",
        "    Input dir\n",
        "            |------Pat1  \n",
        "                      |------img1.dcm  \n",
        "                             img2.dcm  \n",
        "                             ....  \n",
        "                             ....  \n",
        "            |-----Pat2  \n",
        "                     |------img1.dcm  \n",
        "                            img2.dcm  \n",
        "                            ....  \n",
        "                            ....  \n",
        "\n",
        "\n",
        "\n",
        "## Installing the model and its dependencies\n",
        "\n",
        "* Installation is performed using CERR's [***model installer***]( https://github.com/cerr/model_installer).  \n",
        "\n",
        "* A Conda archive containing dependencies is downloaded to the `conda-pack`   \n",
        "  sub-directory of a configurable `scriptInstallDir`.  \n",
        "  By default `condaEnvPath = '/content/MR_Prostate_Deeplab/conda-pack'`\n",
        "  \n",
        "* The inference script is located at   \n",
        "  `scriptInstallDir = os.path.join(condaEnvPath,'model_wrapper', run_inference_nii.py')`  \n",
        "\n",
        "* Running the model\n",
        "```python\n",
        "!python {wrapperPath} {input_nii_directory} {output_nii_directory}\n",
        "```\n",
        "* Data I/O, pre- and post-processing are performed using [***pyCERR***](https://github.com/cerr/pyCERR) ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GVYj7k5e97G"
      },
      "source": [
        "## License\n",
        "\n",
        "By downloading the software you are agreeing to the following terms and conditions as well as to the Terms of Use of CERR software.\n",
        "\n",
        "**`THE SOFTWARE IS PROVIDED \"AS IS\" AND CERR DEVELOPMENT TEAM AND ITS COLLABORATORS DO NOT MAKE ANY WARRANTY, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE, NOR DO THEY ASSUME ANY LIABILITY OR RESPONSIBILITY FOR THE USE OF THIS SOFTWARE.`**\n",
        "\n",
        "`This software is for research purposes only and has not been approved for clinical use.`\n",
        "\n",
        "`Software has not been reviewed or approved by the Food and Drug Administration, and is for non-clinical, IRB-approved Research Use Only. In no event shall data or images generated through the use of the Software be used in the provision of patient care.`\n",
        "  \n",
        "`YOU MAY NOT DISTRIBUTE COPIES of this software, or copies of software derived from this software, to others outside your organization without specific prior written permission from the CERR development team except where noted for specific software products.`\n",
        "\n",
        "`All Technology and technical data delivered under this Agreement are subject to US export control laws and may be subject to export or import regulations in other countries. You agree to comply strictly with all such laws and regulations and acknowledge that you have the responsibility to obtain\n",
        "such licenses to export, re-export, or import as may be required after delivery to you.`\n",
        "\n",
        "**`You may publish papers and books using results produced using software provided you cite the following`**:\n",
        "  \n",
        "  * **AI model**: https://doi.org/10.1016/j.phro.2019.11.006\n",
        "  * **CERR model library**: https://doi.org/10.1016/j.ejmp.2020.04.011\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35nEDWKTg5c1"
      },
      "source": [
        "# Downloads"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mP6FHznIg7Yd"
      },
      "source": [
        "\n",
        "## Download planning MRIs (DICOM)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following can be used to download data from user-specified ***dataUrl*** to ***dataDownloadDir***.\n",
        "\n",
        "See [demo notebook](github.com/cerr/pyCERR-Notebooks/download_data_from_xnat.ipynb) for downloading data from XNAT."
      ],
      "metadata": {
        "id": "zB-PJ6IPTZRl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2cIR2Swg_84"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "workDir = r'/content'          # For Colab\n",
        "#workDir = r'/home/jupyter'\n",
        "dataUrl = 'http://path.to/data'\n",
        "dataDownloadDir = os.path.join(workDir, 'sampleData')\n",
        "os.makedirs(dataDownloadDir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWaGs8LqhZTD"
      },
      "outputs": [],
      "source": [
        "! wget -O sampleData.gz -L {dataUrl}\n",
        "! tar xf sampleData.gz -C {dataDownloadDir}\n",
        "! rm sampleData.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSvE1KsTj9do"
      },
      "source": [
        "Define paths to input DICOM directory, desired output directory, and a session directory to store temporary files during model execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHbUWoUEj1A2"
      },
      "outputs": [],
      "source": [
        "#Paths to input data and conda env with pre-trained models\n",
        "inputDicomPath = os.path.join(dataDownloadDir,'your_dir_name_here')  # Replace with apropriate path to your dataset\n",
        "outputDicomPath = os.path.join(workDir, 'AIoutput')\n",
        "sessionPath = os.path.join(workDir, 'temp')\n",
        "\n",
        "if not os.path.exists(outputDicomPath):\n",
        "  os.mkdir(outputDicomPath)\n",
        "\n",
        "if not os.path.exists(sessionPath):\n",
        "  os.mkdir(sessionPath)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download pre-trained model, inference script, and packaged conda evnironment to ***scriptInstallDir***\n"
      ],
      "metadata": {
        "id": "FC5pCpVa65lK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "os.chdir(workDir)\n",
        "!git clone https://github.com/cerr/model_installer.git\n",
        "os.chdir(os.path.join(workDir,'model_installer'))\n",
        "!./installer.sh -h\n",
        "\n",
        "modelOpt = '3'  # MR_Prostate_DeepLab\n",
        "pythonOpt = 'C' # Download packaged Conda environment\n",
        "\n",
        "! source ./installer.sh -m {modelOpt} -d {workDir} -p {pythonOpt}"
      ],
      "metadata": {
        "id": "32VHeXVxTmt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Location of inference script\n",
        "scriptInstallDir = os.path.join(workDir, 'MR_Prostate_Deeplab')\n",
        "scriptPath = os.path.join(scriptInstallDir,\n",
        "                         'model_wrapper',\n",
        "                         'run_inference_nii.py')\n",
        "\n",
        "# Location of Conda archive\n",
        "condaEnvPath = os.path.join(scriptInstallDir, 'conda-pack')\n",
        "\n",
        "# Location of activation script for Conda environment\n",
        "activateScript = os.path.join(condaEnvPath,'bin','activate')"
      ],
      "metadata": {
        "id": "xuDuWRX9T1Co"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsKXYI-dsgcK"
      },
      "source": [
        "## Install ***pyCERR***\n",
        "\n",
        "pyCERR is used for data import/export and pre- and post-processing transformations needed for this model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRGzE5J7sgcL"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install \"pyCERR[napari] @ git+https://github.com/cerr/pyCERR.git@testing\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfcIIiLQsgcM"
      },
      "source": [
        "# Data processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSxnA1zSHTS_"
      },
      "source": [
        "## Pre-processing\n",
        "\n",
        "### `identifyInputData`: Identify the input scan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfJd7nySHUJJ"
      },
      "outputs": [],
      "source": [
        "import cerr\n",
        "from cerr.utils.ai_pipeline import getScanNumFromIdentifier\n",
        "\n",
        "def identifyInputData(planC):\n",
        "\n",
        "  # Identify scan index in  planC\n",
        "  scanIdS = {\"imageType\": \"MR SCAN\"}\n",
        "  matchScanIdx = getScanNumForIdentifier(scanIdS,\n",
        "                                         planC,\n",
        "                                         False)\n",
        "\n",
        "  return matchScanIdx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1KHjP1LsgcO"
      },
      "source": [
        "\n",
        "## Post-processing\n",
        "\n",
        "### `postProcAndImportSeg`: Import label maps to planC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtPOzqWQsgcP"
      },
      "outputs": [],
      "source": [
        "# Map output labels to structure names\n",
        "strToLabelMap = {1:\"Bladder_O_DLV3\", 2:\"CTV_PROST_DLV3\",\n",
        "                 3:\"Penile_Bulb_DLV3\", 4:\"Rectum_O_DLV3\",\n",
        "                 5:\"Urethra_Foley_DLV3\", 6:\"Rectal_Spacer_DLV3\",\n",
        "                 7: \"Bowel_Lg_DLV3\"}\n",
        "numLabel = len(strToLabelMap)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_GjRVWtsgcP"
      },
      "outputs": [],
      "source": [
        "#Import label map to CERR\n",
        "import glob\n",
        "from cerr import plan_container as pc\n",
        "\n",
        "def postProcAndImportSeg(outputDir,scanNum,planC):\n",
        "  niiGlob = glob.glob(os.path.join(outputDir,'*.nii.gz'))\n",
        "\n",
        "  print('Importing ' + niiGlob[0]+'...')\n",
        "  numStrOrig = len(planC.structure)\n",
        "  planC = pc.loadNiiStructure(niiGlob[0], scanNum, planC, \\\n",
        "                              labels_dict = strToLabelMap)\n",
        "  return planC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zj7t-J4isgcQ"
      },
      "source": [
        "# Segment OARs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XVVLPjBkYI0"
      },
      "source": [
        "## Apply AI model  to all MR scans\n",
        "\n",
        "### located in ***inputDicomPath*** and store auto-segmentation results to ***outputDicomPath***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCuUi5D6sgcS"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import subprocess\n",
        "import numpy as np\n",
        "\n",
        "from cerr.dataclasses import scan as cerrScn\n",
        "from cerr.dcm_export import rtstruct_iod\n",
        "from cerr.utils.ai_pipeline import createSessionDir\n",
        "\n",
        "\n",
        "# Loop over pyCERR files\n",
        "fileList = os.listdir(inputDicomPath)\n",
        "numFiles = len(fileList)\n",
        "modality = 'MR'\n",
        "\n",
        "for iFile in range(numFiles):\n",
        "\n",
        "    inputFilename = fileList[iFile]\n",
        "    dcmDir = os.path.join(inputDicomPath, inputFilename)\n",
        "\n",
        "    # Create session dir to store temporary data\n",
        "    modInputPath, modOutputPath = createSessionDir(sessionPath,\n",
        "                                                   inputDicomPath)\n",
        "\n",
        "    # Import DICOM scan to planC\n",
        "    planC = pc.loadDcmDir(dcmDir)\n",
        "    scanNum = identifyInputData(planC)\n",
        "    numExistingStructs = len(planC.structure)\n",
        "\n",
        "    # Export inputs to NIfTI\n",
        "    scanFilename = os.path.join(modInputPath,\n",
        "                                f\"{inputFilename}_scan_3D.nii.gz\")\n",
        "    planC.scan[scanNum].saveNii(scanFilename)\n",
        "\n",
        "    # Apply model\n",
        "    subprocess.run(f\"source {activateScript} && python {scriptPath} \\\n",
        "                  {modInputPath} {modOutputPath}\", \\\n",
        "                  capture_output=False, shell=True, executable=\"/bin/bash\")\n",
        "\n",
        "    # Import results to planC\n",
        "    planC = postProcAndImportSeg(modOutputPath, scanNum, planC)\n",
        "    newNumStructs = len(planC.structure)\n",
        "\n",
        "    # Export segmentations to DICOM\n",
        "    structFileName = inputFilename + '_AI_seg.dcm'\n",
        "    structFilePath = os.path.join(outputDicomPath, structFileName)\n",
        "    seriesDescription = \"AI Generated\"\n",
        "    exportOpts = {'seriesDescription': seriesDescription}\n",
        "\n",
        "    structNumV = np.arange(numExistingStructs, newNumStructs)\n",
        "    indOrigV = np.array([cerrScn.getScanNumFromUID(planC.structure[structNum].assocScanUID,\\\n",
        "                        planC) for structNum in structNumV], dtype=int)\n",
        "    structsToExportV = structNumV[indOrigV == scanNum]\n",
        "    rtstruct_iod.create(structsToExportV, structFilePath, planC, exportOpts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kugws3KBl4MK"
      },
      "source": [
        "## **Optional**: Uncomment the following to download the output segmentations to your workspace bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nkTBkijl23J"
      },
      "outputs": [],
      "source": [
        "# workspaceBucket = os.environ['WORKSPACE_BUCKET']\n",
        "# !gcloud storage cp -r {outputDicomPath} {workspaceBucket}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLzFp-l_sgcT"
      },
      "source": [
        "# Display results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8FTwNqhsgcT"
      },
      "source": [
        "## Overlay AI segmentations on scan for visualization using ***Matplotlib***\n",
        "\n",
        "Note: This example displays the last segmented dataset by default.    \n",
        "Load the appropriate pyCERR archive to `planC` to view results for desired dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWQD1KeVsgcT"
      },
      "outputs": [],
      "source": [
        "from cerr.viewer import showMplNb\n",
        "\n",
        "showMplNb(planC=planC, scan_nums=scanNum,\n",
        "          struct_nums=structsToExportV,\n",
        "          windowCenter=1100, windowWidth=2250)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
