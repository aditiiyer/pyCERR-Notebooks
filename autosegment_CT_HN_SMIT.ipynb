{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A7EP6563vQHy"
   },
   "source": [
    "# The pyCERR SMIT HN CT Segmentation Model\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this tutorial, we will demonstrate how to apply a pre-trained AI model to segment the OAR in head-and-neck region on a planning CT scan using pyCERR.\n",
    "\n",
    "## Requirements\n",
    "* Python>=3.8 (for pyCERR)\n",
    "* Applying this model requires access to a A100-caliber Tensor Core GPU.\n",
    "\n",
    "## AI model\n",
    "* The segmentation model was trained and validated on CT scans used for RT planning. It does not work optimally on diagnostic CTs or scans in positions other than Head First Supine.\n",
    "* The trained model is distributed along with python libraries and other dependencies via a conda package.\n",
    "\n",
    "## Required input data\n",
    "* RT planning CT DICOM\n",
    "\n",
    "### Running the model\n",
    "\n",
    "Update locations of input data and model directorues in section 2 of this notebook.\n",
    "* Conda packge is location: `condaEnvDir`\n",
    "* Inference script location: `wrapperPath`\n",
    "* Inference script args\n",
    "\n",
    "\n",
    "### License\n",
    "By downloading the software you are agreeing to the following terms and conditions as well as to the Terms of Use of CERR software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\" AND CERR DEVELOPMENT TEAM AND ITS COLLABORATORS DO NOT MAKE ANY WARRANTY, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE, NOR DO THEY ASSUME ANY LIABILITY OR RESPONSIBILITY FOR THE USE OF THIS SOFTWARE.\n",
    "    \n",
    "This software is for research purposes only and has not been approved for clinical use.\n",
    "\n",
    "Software has not been reviewed or approved by the Food and Drug Administration, and is for non-clinical, IRB-approved Research Use Only. In no event shall data or images generated through the use of the Software be used in the provision of patient care.\n",
    "\n",
    "You may publish papers and books using results produced using software provided that you reference the appropriate citations:\n",
    "*  SMIT model: https://arxiv.org/abs/2205.10342\n",
    "*  CERR library of model implementations: https://doi.org/10.1016/j.ejmp.2020.04.011\n",
    "*  CERR software: https://doi.org/10.1118/1.1568978\n",
    "*  CERR radiomics: https://doi.org/10.1002/mp.13046\n",
    "\n",
    "\n",
    "YOU MAY NOT DISTRIBUTE COPIES of this software, or copies of software derived from this software, to others outside your organization without specific prior written permission from the CERR development team except where noted for specific software products.\n",
    "\n",
    "All technology and technical data delivered under this Agreement are subject to US export control laws and may be subject to export or import regulations in other countries. You agree to comply strictly with all such laws and regulations and acknowledge that you have the responsibility to obtain such licenses to export, re-export, or import as may be required after delivery to you.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qXxnhPPy3TrK"
   },
   "outputs": [],
   "source": [
    "import os, subprocess\n",
    "from glob import glob\n",
    "import shutil\n",
    "# work dir, set to your desired working directory\n",
    "workDir = r'/home/user/hn_oar_smit_model'\n",
    "os.makedirs(workDir,exist_ok=True)\n",
    "os.chdir(workDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-cG1gAx69axp",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "#!pip install pyxnat\n",
    "! pip install \"pyCERR[napari] @ git+https://github.com/cerr/pyCERR.git@testing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lgck3qYo607q"
   },
   "outputs": [],
   "source": [
    "inputDicomPath = os.path.join(workDir,'input')\n",
    "os.makedirs(inputDicomPath, exist_ok = True)\n",
    "\n",
    "outputDicomPath = os.path.join(workDir, 'output')\n",
    "os.makedirs(outputDicomPath, exist_ok = True)\n",
    "\n",
    "sessionPath = os.path.join(workDir, 'session')\n",
    "os.makedirs(sessionPath, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DoEXYr3GDaf_"
   },
   "source": [
    "## Download planning CT DICOM data for processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Le2MiPpjOuWl"
   },
   "source": [
    "### Option 1: Download data from XNAT source (`getXNATData`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tc5z7BJ8jJas"
   },
   "outputs": [],
   "source": [
    "# # Function definition: pull data defined in scandict from XNAT\n",
    "# from pyxnat import Interface\n",
    "# import urllib3, shutil\n",
    "\n",
    "# def getXNATData(xhost,user,scandict,downloadDir):\n",
    "#   xnat = Interface(xhost, user, verify=False)\n",
    "#   os.makedirs(downloadDir, exist_ok=True)\n",
    "#   expdirlist = []\n",
    "#   for scan_entry in scandict:\n",
    "#     proj = scan_entry['proj']\n",
    "#     subj = scan_entry['subj']\n",
    "#     exp = scan_entry['exp']\n",
    "#     scan_list = scan_entry['scan_list']\n",
    "#     expdir = os.path.join(downloadDir,exp)\n",
    "#     expdirlist.append(expdir)\n",
    "#     os.makedirs(expdir, exist_ok = True)\n",
    "#     xexp = xnat.select.project(proj).subject(subj).experiment(exp)\n",
    "#     for scan in scan_list:\n",
    "#       try:\n",
    "#         xnat.select.project(proj).subject(subj).experiment(exp).scan(scan).resource('DICOM').get(downloadDir,extract=True)\n",
    "#       except:\n",
    "#         xnat.select.project(proj).subject(subj).experiment(exp).scan(scan).resource('secondary').get(downloadDir,extract=True)\n",
    "#     for dcmfolder in ['DICOM','secondary']:\n",
    "#       dcmlist = glob(os.path.join(downloadDir,dcmfolder,'*.dcm'))\n",
    "#       print(dcmlist)\n",
    "#       for dcm in dcmlist:\n",
    "#         shutil.move(dcm, expdir)\n",
    "#   for dcmfolder in ['DICOM','secondary']:\n",
    "#     if os.path.exists(os.path.join(downloadDir,dcmfolder)):\n",
    "#       os.rmdir(os.path.join(downloadDir,dcmfolder))\n",
    "#     if os.path.exists(os.path.join(downloadDir,dcmfolder + '.zip')):\n",
    "#       os.remove(os.path.join(downloadDir,dcmfolder + '.zip'))\n",
    "#   xnat.disconnect()\n",
    "#   return expdirlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yc4ZOtlK7c0f"
   },
   "outputs": [],
   "source": [
    "# xhost = 'https://your.xnat'\n",
    "# user = 'usr'\n",
    "# scandict = [{'proj':'projectname','subj':'subject_ID','exp':'ID', 'scan_list':['1']}]\n",
    "\n",
    "# dcmdirlist = getXNATData(xhost,user,scandict,inputDicomPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5pzpm9yhHqH"
   },
   "source": [
    "### Option 2:  Download data from other HTTP or BOX source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iiNCD-z8hFe_"
   },
   "outputs": [],
   "source": [
    "# dataURL = 'http://datapath'\n",
    "# dataDownloadDir = os.path.join(workDir,'tmp')\n",
    "# os.makedirs(dataDownloadDir, exist_ok=True)\n",
    "# os.chdir(dataDownloadDir)\n",
    "\n",
    "# ! wget -O sampleData.gz -L {dataURL}\n",
    "# ! tar xf sampleData.gz -C {inputDicomDir}\n",
    "# ! rm sampleData.gz\n",
    "\n",
    "# #unpack and move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dcmdirlist = glob(os.path.join(workDir,'input','*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 3: Copy data from network share to `inputDicomPath`, or set `inputDicomPath` to location where your data resides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDicomPath = r'/path/to/dicom/dirs'\n",
    "dcmdirlist = [os.path.join(inputDicomPath,x) for x in os.listdir(inputDicomPath) if x[:3] == 'HNC']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare to analyze data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nRx8hP0prcnD"
   },
   "outputs": [],
   "source": [
    "os.chdir(workDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PIagq_xEIFlZ"
   },
   "outputs": [],
   "source": [
    "wrapperInstallDir = os.path.join(workDir,'CT_HN_SMIT')\n",
    "condaEnvDir = os.path.join(wrapperInstallDir,'conda-pack')\n",
    "condaEnvActivateScript = os.path.join(condaEnvDir, 'bin', 'activate')\n",
    "wrapperPath = os.path.join(wrapperInstallDir,'bash_run_SMIT_Segmentation.sh')\n",
    "model_basename = 'CT_HN_15_15_15'\n",
    "load_weight_name = os.path.join(wrapperInstallDir,'trained_weights',model_basename + '.pt')\n",
    "\n",
    "#pyCERR and filename parameters\n",
    "scanNum = 0 # assume we are analyzing first scan in planC.scan/session data directory\n",
    "scan_basename = 'CT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0tIFXpPmDV4b"
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from cerr import plan_container as pc\n",
    "from cerr.dcm_export import rtstruct_iod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t5461VKM6UQf",
    "outputId": "1ad7f244-a1c9-442c-8403-32ef7db17baa"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/cerr/model_installer.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b-dncPq06WQ6",
    "outputId": "9f49f79e-632b-46f3-db10-33d04db57541"
   },
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(workDir,'model_installer'))\n",
    "\n",
    "!./installer.sh -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wMjeeay86fu6",
    "outputId": "0e49b412-4bba-4fb9-f8f9-1193375f81c7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "modelOpt = '7' #CT_HN_SMIT model\n",
    "pythonOpt = 'C' #download and use pre-packaged Conda environment\n",
    "\n",
    "! source ./installer.sh -m {modelOpt} -d {workDir} -p {pythonOpt}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "95vm9iDGDGfE"
   },
   "source": [
    "## Run the HN segmentation model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import DICOM with pycerr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dcmdirlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = {1:'Brainstem',2:'Parotid_L',3:'Parotid_R',4:'Glnd_Submand_L',5:'Glnd_Submand_R',6:'Bone_Mandible',7:'Cavity_Oral',8:'SpinalCord',9:'Pterygoid_Lat_L',10:'Pterygoid_Lat_R',11:'Musc_Masseter_L',12:'Musc_Masseter_R',13:'Cartlg_Thyroid',14:'BrachialPlex_L',15:'BrachialPlex_R',16:'Larynx'}\n",
    "structName = 'CT_HN_SMIT_plus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MasJhWdZCdoJ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for dcmdir in dcmdirlist[:1]:\n",
    "  subj = os.path.basename(dcmdir)\n",
    "  sessiondir = os.path.join(sessionPath,subj)\n",
    "  os.makedirs(sessiondir,exist_ok=True)\n",
    "\n",
    "  #Convert input DICOM to NIfTI\n",
    "  scan_niifile = os.path.join(sessiondir, scan_basename + '.nii')\n",
    "  planC = pc.loadDcmDir(dcmDir = dcmdir)\n",
    "  planC.scan[scanNum].saveNii(niiFileName = scan_niifile)\n",
    "\n",
    "  numOrigStructs = len(planC.structure)\n",
    "\n",
    "  #Run Segmentation\n",
    "  os.chdir(wrapperInstallDir)\n",
    "  cmd = f\"source \" + condaEnvActivateScript + \" && source \" + wrapperPath + \" \" + sessiondir + \" \" + sessiondir + \" \" + load_weight_name + \" \" + scan_niifile\n",
    "  subprocess.run(cmd, shell=True, executable=\"/bin/bash\")\n",
    "\n",
    "  #Import output GTV NIfTI to pyCERR, and generate RTSTRUCT to match parent series\n",
    "  output_niifile = os.path.join(sessiondir, model_basename + '_' + scan_basename + '.nii')\n",
    "  planC = pc.loadNiiStructure(nii_file_name = output_niifile, assocScanNum = scanNum, planC = planC, labels_dict = labels_dict)\n",
    "  numStructs = len(planC.structure)\n",
    "  \n",
    "  # Output segmentation to RTSTRUCT\n",
    "  outputDir = os.path.join(workDir,'output')\n",
    "  os.makedirs(outputDir, exist_ok=True)\n",
    "  rtstructFile = os.path.join(outputDir, subj + '_RTSTRUCT.dcm')\n",
    "  structNumV = range(numOrigStructs, numStructs) # Export the first and the last structure in the list\n",
    "  seriesDescription = structName\n",
    "  rtstruct_iod.create(structNumV = structNumV, filePath = rtstructFile, planC = planC, seriesOpts = {'SeriesDescription':seriesDescription})\n",
    "\n",
    "  # remove session directory\n",
    "  shutil.rmtree(sessiondir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cerr.viewer import showMplNb\n",
    "showMplNb(planC=planC, scan_nums=scanNum,\n",
    "          struct_nums=structNumV, dose_nums=[],\n",
    "          windowCenter=-400, windowWidth=2000)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
