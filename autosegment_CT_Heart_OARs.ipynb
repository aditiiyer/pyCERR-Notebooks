{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/cerr/pycerr-notebooks/blob/main/autosegment_CT_Heart_OARs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kNoydh-RsgcD"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "In this tutorial, we will demonstrate how to apply a pre-trained AI model to segment the Heart sub-structures on a lung CT scan using pyCERR.\n",
    "\n",
    "## AI model\n",
    "* The segmentation model was trained and validated on CT scans used for RT planning. It does not work optimally on diagnostic CTs or scans in positions other than Head First Supine.\n",
    "* The trained model is distributed along with python libraries and other dependencies via a conda package.\n",
    "* The model requires acess to a GPU.\n",
    "\n",
    "### Running the model\n",
    "\n",
    "* Conda packge is location: condaEnvDir\n",
    "* Inference script location: wrapperPath\n",
    "\n",
    "```python\n",
    "!python {wrapperPath} {input_nii_directory} {output_nii_directory}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DsKXYI-dsgcK"
   },
   "source": [
    "# Install pyCERR\n",
    "\n",
    "pyCERR is used for pre and post-processing of DICOM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XRGzE5J7sgcL"
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/cerr/pyCERR.git@testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pnoZxbKnsgcG"
   },
   "source": [
    "# Download pretrained segmentation model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the pre-packaged Anaconda environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pUc1tZzbsgcK"
   },
   "outputs": [],
   "source": [
    "# Location of LungOAR conda environment\n",
    "heartCondaEnvDir ='/content/pretrainedHeartModel'\n",
    "\n",
    "# Download packaged environment for the Heart segmentation model\n",
    "boxLink = 'https://mskcc.box.com/shared/static/o524xsg5s91q0frwka10fvsf82395sgg.gz'\n",
    "saveFileName = 'ct_heart_oar.tar.gz'\n",
    "\n",
    "!mkdir -p {heartCondaEnvDir}\n",
    "!wget {boxLink} -O {saveFileName}\n",
    "!tar xf {saveFileName} -C {heartCondaEnvDir}\n",
    "!rm {saveFileName}\n",
    "\n",
    "# Path to conda environment activate script\n",
    "heartEnvActivateScript = heartCondaEnvDir + '/bin/activate'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the inference script and model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "wrapperInstallDir = '/content/CT_cardiac_structures_deeplab'\n",
    "!git clone https://github.com/cerr/CT_cardiac_structures_deeplab.git {wrapperInstallDir}\n",
    "wrapperPath = os.path.join(wrapperInstallDir, 'model_wrapper','runSegmentation.py')\n",
    "modelWeightZipPath = os.path.join(wrapperInstallDir,'model.gz')\n",
    "modelWeightPath = os.path.join(wrapperInstallDir,'model')\n",
    "!wget -O {modelWeightZipPath} -L https://mskcc.box.com/shared/static/o524xsg5s91q0frwka10fvsf82395sgg.gz\n",
    "!tar xf {modelWeightZipPath} -C {wrapperInstallDir}\n",
    "!rm {modelWeightZipPath}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sfcIIiLQsgcM"
   },
   "source": [
    "# Functions for data pre- and post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1m955pAJsgcN"
   },
   "source": [
    "## Crop scan to Lung extents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FAXBqkTasgcN"
   },
   "outputs": [],
   "source": [
    "from cerr.dataclasses import structure as cerrStr\n",
    "from cerr.contour import rasterseg as rs\n",
    "from cerr.utils import identifyScan, imageProc\n",
    "from cerr.utils import bbox\n",
    "import numpy as np\n",
    "\n",
    "def processInputData(scanNum, planC, lungNameList=['Lung_total', 'Lung_L', 'Lung_R']):\n",
    "\n",
    "    if isinstance(lungNameList, str):\n",
    "        lungNameList = [lungNameList]\n",
    "        \n",
    "    # Extract scanArray\n",
    "    scan3M = planC.scan[scanNum].getScanArray()\n",
    "    mask3M = np.zeros(scan3M.shape)\n",
    "\n",
    "    # List of Structure names\n",
    "    strNames = [s.structureName for s in planC.structure]\n",
    "    numOrigStructs = len(strNames)\n",
    "    \n",
    "    # Get total lung mask\n",
    "    for lungName in lungNameList:\n",
    "        lungInd = cerrStr.getMatchingIndex(lungName, strNames, 'exact')    \n",
    "        if len(lungInd) > 0:\n",
    "            # Get lung extents\n",
    "            mask3M = mask3M & rs.getStrMask(lungInd[0], planC)\n",
    "    \n",
    "    if not np.any(mask3M):\n",
    "        raise Exception('Lung contour name did not match any structures in planC')\n",
    "\n",
    "    # Create cropped scan\n",
    "    rmin,rmax,cmin,cmax,smin,smax,_ = bbox.compute_boundingbox(mask3M)\n",
    "    x,y,z = planC.scan[0].getScanXYZVals()\n",
    "    xCropV = x[cmin:cmax]\n",
    "    yCropV = y[rmin:rmax]\n",
    "    zCropV = z[smin:smax]\n",
    "    scan3M = planC.scan[0].getScanArray()\n",
    "    scanCrop3M = scan3M[rmin:rmax,cmin:cmax,smin:smax]\n",
    "\n",
    "    return scanCrop3M, (xCropV, yCropV, zCropV)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1KHjP1LsgcO"
   },
   "source": [
    "## Import and refine AI segmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W_GjRVWtsgcP"
   },
   "outputs": [],
   "source": [
    "#Import label map to CERR\n",
    "import glob\n",
    "from cerr import plan_container as pc\n",
    "\n",
    "atriaLabelDict = {1: 'DL_Atria'}\n",
    "heartSubSegDict = {2: 'AORTA', 3: 'DL_LA',\n",
    "                   4: 'DL_LV', 5: 'DL_RA',\n",
    "                   6: 'DL_RV', 7: 'DL_IVC',\n",
    "                   8: 'DL_SVC', 9: 'DL_PA'}\n",
    "heartSegDict = {1: 'DL_heart'}\n",
    "periLabelDict = {1: 'DL_Pericardium'}\n",
    "ventriLabelDict = {1: 'DL_Ventricles'}\n",
    "\n",
    "def postProcAndImportSeg(outputDir,procScanNum,scanNum,planC):\n",
    "    niiGlob = glob.glob(os.path.join(outputDir,'*.nii.gz'))\n",
    "    for segFile in niiGlob:\n",
    "        print('Importing ' + niiGlob[0]+'...')\n",
    "        # Get segFile name\n",
    "        if 'heart.nii.gz' in segFile:\n",
    "            strToLabelMap = heartSubSegDict\n",
    "        elif 'heartStructure.nii.gz' in segFile:\n",
    "            strToLabelMap = heartSegDict\n",
    "        elif 'atria.nii.gz' in segFile:\n",
    "            strToLabelMap = atriaLabelDict\n",
    "        elif 'pericardium.nii.gz' in segFile:\n",
    "            strToLabelMap = periLabelDict\n",
    "        elif 'ventricles.nii.gz' in segFile:\n",
    "            strToLabelMap = ventriLabelDict\n",
    "        numLabel = len(strToLabelMap)\n",
    "        numStrOrig = len(planC.structure)\n",
    "        planC = pc.load_nii_structure(segFile, procScanNum, planC, \\\n",
    "                                  labels_dict = strToLabelMap)\n",
    "        cpyStrNumV = np.arange(numStrOrig,len(planC.structure))\n",
    "        numComponents = 1\n",
    "        for label in range(numLabel):\n",
    "            # Copy to original scan\n",
    "            planC = structure.copyToScan(cpyStrNumV[label], scanNum, planC)\n",
    "            origStr = len(planC.structure)-1\n",
    "            mask3M = rs.getStrMask(origStr,planC)\n",
    "            # Post-process\n",
    "            procMask3M = imageProc.getLargestConnComps(mask3M,numComponents)\n",
    "            strName =  strToLabelMap[label+1]\n",
    "            planC = pc.import_structure_mask(procMask3M, scanNum, strName, [], planC)\n",
    "            # Delete original\n",
    "            del planC.structure[origStr]\n",
    "\n",
    "  return planC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zj7t-J4isgcQ"
   },
   "source": [
    "# Segment OARs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDB-RjRQsgcQ"
   },
   "source": [
    "## Define I/O paths\n",
    "\n",
    "Specify paths to the DICOM input data, desired output directory, and temporary (session) directory used to store intermediate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lzcaNT4SsgcR"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#Paths to input data and conda env with pre-trained models\n",
    "inputDicomPath = '/content/sampleData/'  # Replace with path to dataset\n",
    "outputDicomPath = '/content/AIoutput/'\n",
    "sessionPath = '/content/temp'\n",
    "\n",
    "if not os.path.exists(outputDicomPath):\n",
    "  os.mkdir(outputDicomPath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GbB7NyKgsgcR"
   },
   "source": [
    "## Run AI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WCuUi5D6sgcS"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import cerr\n",
    "from cerr import plan_container as pc\n",
    "from cerr.ai import createSessionDir as cdir\n",
    "from cerr.dcm_export import rtstruct_iod\n",
    "\n",
    "# Loop over pyCERR files\n",
    "fileList = os.listdir(inputDicomPath)\n",
    "numFiles = len(fileList)\n",
    "modality = 'CT SCAN'\n",
    "\n",
    "for iFile in range(numFiles):\n",
    "\n",
    "    dcmDir = os.path.join(inputDicomPath,fileList[iFile])\n",
    "\n",
    "    # Create session dir to store temporary data\n",
    "    modInputPath, modOutputPath = cdir.createSessionDir(sessionPath, inputDicomPath)\n",
    "\n",
    "    # Import DICOM to planC\n",
    "    planC = pc.load_dcm_dir(dcmDir)\n",
    "\n",
    "    # Identify scan index in  planC\n",
    "    scanIdS = {\"imageType\": modality}\n",
    "    matchScanV = identifyScan.getScanNumForIdentifier(scanIdS, planC, False)\n",
    "    scanNum = matchScanV[0]\n",
    "    \n",
    "    # Pre-process data\n",
    "    procScan3M, resizeGridS = processInputData(planC)\n",
    "    planC = pc.import_scan_array(procScan3M, resizeGridS[0], \\\n",
    "            resizeGridS[1], resizeGridS[2], modality, scanNum, planC)\n",
    "    procScanNum = len(planC.scan) - 1\n",
    "\n",
    "    # Export inputs to NIfTI\n",
    "    scanFilename = os.path.join(modInputPath, f\"{fileList[iFile]}_scan_3D.nii.gz\")\n",
    "    planC.scan[procScanNum].save_nii(scanFilename)\n",
    "\n",
    "    # Apply model\n",
    "    subprocess.run(f\"source {heartEnvActivateScript} && python {wrapperPath} \\\n",
    "                  {modInputPath} {modOutputPath}\", \\\n",
    "                  capture_output=False,shell=True,executable=\"/bin/bash\")\n",
    "\n",
    "    # Import results to planC\n",
    "    planC = postProcAndImportSeg(modOutputPath,procScanNum,scanNum,planC)\n",
    "\n",
    "    # Export segmentations to DICOM\n",
    "    structFileName = fileList[iFile] + '_AI_seg.dcm'\n",
    "    structFilePath = os.path.join(outputDicomPath,structFileName)\n",
    "    structNumV = list(np.arange(len(planC.structure)-numLabel,\\\n",
    "                                len(planC.structure)))\n",
    "    seriesDescription = \"AI Generated\"\n",
    "    exportOpts = {'seriesDescription': seriesDescription}\n",
    "    rtstruct_iod.create(structNumV,structFilePath,planC,exportOpts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iLzFp-l_sgcT"
   },
   "source": [
    "# Display results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L8FTwNqhsgcT"
   },
   "source": [
    "## Display using matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "cc37a35a904045c1bfeb1a75b8b0658f",
      "70c61bbc29d9485e8ec87e2f37ceb0e6",
      "62cd7c5b0f4a44c18a2a021649c3a6d3"
     ]
    },
    "id": "jWQD1KeVsgcT",
    "outputId": "59375a64-93ae-4a95-c898-41b7170adde8"
   },
   "outputs": [],
   "source": [
    "from cerr.viewer import showMplNb\n",
    "\n",
    "showMplNb(scanNum, structNumV, planC,\\\n",
    "          windowCenter=-400, windowWidth=2000)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
